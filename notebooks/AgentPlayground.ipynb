{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7766cf-75a4-4370-ba70-573e88e5d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 13:15:05.817 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to /root/workspace/StreamChatPlayground/notebooks\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from utils.common import load_plaintext\n",
    "\n",
    "# debug level\n",
    "from metagpt.logs import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "# make asyncio.run() works in notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f34c9",
   "metadata": {},
   "source": [
    "## LLM 与 tools 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f19600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 智普AI\n",
    "# ~/.metagpt/config2.yaml\n",
    "from metagpt.config2 import config\n",
    "from metagpt.provider.zhipuai_api import ZhiPuAILLM\n",
    "# from metagpt.utils.cost_manager import CostManager\n",
    "\n",
    "llm = ZhiPuAILLM(config.llm)\n",
    "llm.use_system_prompt = False # Disable default system message\n",
    "# llm.cost_manager = CostManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ead1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm 本地\n",
    "import yaml\n",
    "from metagpt.configs.llm_config import LLMConfig\n",
    "from metagpt.provider.openai_api import OpenAILLM\n",
    "# from metagpt.utils.cost_manager import CostManager\n",
    "\n",
    "llm_configs = yaml.safe_load(load_plaintext(\"../\", \"vllm_local.yaml\"))\n",
    "llm_config = LLMConfig.model_validate(llm_configs['llm'])\n",
    "llm = OpenAILLM(llm_config)\n",
    "llm.use_system_prompt = False # Disable default system message\n",
    "# llm.cost_manager = CostManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06449968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 13:17:43.574 | DEBUG    | metagpt.provider.base_llm:aask:149 - [{'role': 'user', 'content': '你好，介绍下你自己'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个大型语言模型（LLM），由 Google 开发。我的目标是在各种任务上提供信息和帮助, 包括代码编程、自然語言处理 (NLP)、图像识别等. 我可以根据您的请求进行交互并生成不同形式的响应或内容 。\n",
      "Warning: model not found. Using cl100k_base encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-24 13:17:52.337 | WARNING  | metagpt.provider.openai_api:_calc_usage:244 - usage calculation failed: num_tokens_from_messages() is not implemented for model google/gemma-7b-it. See https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken for information on how messages are converted to tokens.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我是一个大型语言模型（LLM），由 Google 开发。我的目标是在各种任务上提供信息和帮助, 包括代码编程、自然語言处理 (NLP)、图像识别等. 我可以根据您的请求进行交互并生成不同形式的响应或内容 。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache\n",
    "def llm_aask(msg):\n",
    "    return asyncio.run(llm.aask(msg=msg))\n",
    "\n",
    "llm_aask(\"你好，介绍下你自己\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec60a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**web scraping**: Asynchronously Scrape and save the HTML structure and inner text content of a web page using Playwright. \n",
      "**text extractor**: Perform extraction on the 'content' text using a large language model. \n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from metagpt.tools.tool_convert import function_docstring_to_schema\n",
    "from metagpt.tools.libs.web_scraping import scrape_web_playwright\n",
    "from tools.text_extractor.llm_extractor import llm_extractor\n",
    "\n",
    "def function_to_schema(func):\n",
    "    docstring = inspect.getdoc(func)\n",
    "    schema = function_docstring_to_schema(func, docstring)\n",
    "    schema[\"imports\"] = f\"from {func.__module__} import {func.__name__}\"\n",
    "    return schema\n",
    "\n",
    "DEF_TOOLS = [\n",
    "    (\"web scraping\", scrape_web_playwright),\n",
    "    (\"text extractor\", llm_extractor),\n",
    "]\n",
    "tools = {}\n",
    "for name, func in DEF_TOOLS:\n",
    "    schema = function_to_schema(func)\n",
    "    tools[name] = schema\n",
    "\n",
    "task_types = \"\\n\".join([\n",
    "    f\"**{k}**: {v['description']}\" for k,v in tools.items()\n",
    "])\n",
    "print(task_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7def00e",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23786658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from metagpt.schema import Plan, Task\n",
    "from metagpt.utils.common import OutputParser\n",
    "\n",
    "\n",
    "def load_prompts(path: str) -> PromptTemplate:\n",
    "    base_path = os.path.join(\"prompts\", path)\n",
    "    output_format = load_plaintext(base_path, \"output.md\")\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template=load_plaintext(base_path, \"template.yaml\"),\n",
    "    )\n",
    "    return prompt.partial(output=output_format)\n",
    "\n",
    "def parse_json(rsp):\n",
    "    try:\n",
    "        objs = json.loads(rsp)\n",
    "    except:\n",
    "        code_block = OutputParser.parse_code(rsp, \"json\")\n",
    "        objs = json.loads(code_block)\n",
    "    return objs\n",
    "\n",
    "def create_plan(goal, guidance):\n",
    "    plan_prompt = load_prompts(\"planning\")\n",
    "    template = plan_prompt.format(\n",
    "        goal=goal,\n",
    "        user_guidance=guidance,\n",
    "        task_types=task_types,\n",
    "        max_tasks=20,\n",
    "    )\n",
    "    logger.debug(template)\n",
    "\n",
    "    plan = Plan(goal=goal)\n",
    "    rsp = llm_aask(msg=template)\n",
    "\n",
    "    tasks_json = parse_json(rsp)\n",
    "    tasks = [Task(**task_config) for task_config in tasks_json]\n",
    "    logger.debug(tasks)\n",
    "\n",
    "    plan.add_tasks(tasks)\n",
    "    return plan\n",
    "\n",
    "\n",
    "user_goal = \"抓取 https://pitchhub.36kr.com/financing-flash 中'快讯'的内容，并整理成markdown存档\"\n",
    "user_guidance = \"\"\"大概的流程：\n",
    "- 使用工具抓取网页中的可见文本\n",
    "- 提取网页文本中'快讯'相关的内容。注意网页中可能包含导航，只需要抽取'快讯'的具体内容\n",
    "- 对抽取结果进行归类，并保存成markdown表格: 快讯.md\"\"\"\n",
    "\n",
    "plan = create_plan(goal=user_goal, guidance=user_guidance)\n",
    "plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a73f9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task(task_id='1', dependent_task_ids=[], instruction='使用工具抓取网页中的可见文本。', task_type='web scraping', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='2', dependent_task_ids=['1'], instruction=\"提取网页文本中'快讯'相关的内容。\", task_type='text extractor', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='3', dependent_task_ids=['2'], instruction='对抽取结果进行归类，并保存成markdown表格: 快讯.md。', task_type='text extractor', code='', result='', is_success=False, is_finished=False)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(plan.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669eb4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
