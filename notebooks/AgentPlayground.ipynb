{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba7766cf-75a4-4370-ba70-573e88e5d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "# make asyncio.run() works in notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06449968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<metagpt.provider.zhipuai_api.ZhiPuAILLM at 0x7fd5e4bce380>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from metagpt.config2 import Config\n",
    "from metagpt.provider.llm_provider_registry import create_llm_instance\n",
    "from metagpt.utils.cost_manager import CostManager\n",
    "\n",
    "cfg = Config.default()\n",
    "\n",
    "llm = create_llm_instance(cfg.llm)\n",
    "# llm.cost_manager = CostManager()\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe46e66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course, I'm here to help. How can I assist you"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 23:03:23.170 | INFO     | metagpt.utils.cost_manager:update_cost:57 - Total running cost: $0.000 | Max budget: $10.000 | Current cost: $0.000, prompt_tokens: 14, completion_tokens: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " today?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Of course, I'm here to help. How can I assist you today?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asyncio.run(llm.aask(\"你好\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a875c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, Union, Literal\n",
    "\n",
    "from metagpt.logs import logger\n",
    "from metagpt.roles import Role\n",
    "from metagpt.schema import Message, Task, TaskResult\n",
    "\n",
    "from metagpt.actions.di.execute_nb_code import ExecuteNbCode\n",
    "from metagpt.actions.di.write_analysis_code import CheckData, WriteAnalysisCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccba43e-1bd3-4ea0-a417-5e393f3a0c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeInterpreter(Role):\n",
    "    name: str = \"OpenDevin\"\n",
    "    profile: str = \"CodeInterpreter\"\n",
    "    auto_run: bool = True\n",
    "    use_plan: bool = True\n",
    "    use_reflection: bool = False\n",
    "    execute_code: ExecuteNbCode = Field(default_factory=ExecuteNbCode, exclude=True)\n",
    "    tools: Union[str, list[str]] = []  # Use special symbol [\"<all>\"] to indicate use of all registered tools\n",
    "    react_mode: Literal[\"plan_and_act\", \"react\"] = \"plan_and_act\"\n",
    "    max_react_loop: int = 10  # used for react mode\n",
    "\n",
    "    @property\n",
    "    def working_memory(self):\n",
    "        return self.rc.working_memory\n",
    "\n",
    "    async def _think(self) -> bool:\n",
    "        \"\"\"Useful in 'react' mode. Use LLM to decide whether and what to do next.\"\"\"\n",
    "        user_requirement = self.get_memories()[0].content\n",
    "        context = self.working_memory.get()\n",
    "\n",
    "        if not context:\n",
    "            # just started the run, we need action certainly\n",
    "            self.working_memory.add(self.get_memories()[0])  # add user requirement to working memory\n",
    "            self._set_state(0)\n",
    "            return True\n",
    "\n",
    "        prompt = REACT_THINK_PROMPT.format(user_requirement=user_requirement, context=context)\n",
    "        rsp = await self.llm.aask(prompt)\n",
    "        rsp_dict = json.loads(CodeParser.parse_code(block=None, text=rsp))\n",
    "        self.working_memory.add(Message(content=rsp_dict[\"thoughts\"], role=\"assistant\"))\n",
    "        need_action = rsp_dict[\"state\"]\n",
    "        self._set_state(0) if need_action else self._set_state(-1)\n",
    "\n",
    "        return need_action\n",
    "\n",
    "    async def _act(self) -> Message:\n",
    "        \"\"\"Useful in 'react' mode. Return a Message conforming to Role._act interface.\"\"\"\n",
    "        code, _, _ = await self._write_and_exec_code()\n",
    "        return Message(content=code, role=\"assistant\", cause_by=WriteAnalysisCode)\n",
    "\n",
    "    async def _plan_and_act(self) -> Message:\n",
    "        rsp = await super()._plan_and_act()\n",
    "        await self.execute_code.terminate()\n",
    "        return rsp\n",
    "\n",
    "    async def _act_on_task(self, current_task: Task) -> TaskResult:\n",
    "        \"\"\"Useful in 'plan_and_act' mode. Wrap the output in a TaskResult for review and confirmation.\"\"\"\n",
    "        code, result, is_success = await self._write_and_exec_code()\n",
    "        task_result = TaskResult(code=code, result=result, is_success=is_success)\n",
    "        return task_result\n",
    "\n",
    "    async def _write_and_exec_code(self, max_retry: int = 3):\n",
    "        counter = 0\n",
    "        success = False\n",
    "\n",
    "        # plan info\n",
    "        plan_status = self.planner.get_plan_status() if self.use_plan else \"\"\n",
    "\n",
    "        # tool info\n",
    "        if self.tools:\n",
    "            context = (\n",
    "                self.working_memory.get()[-1].content if self.working_memory.get() else \"\"\n",
    "            )  # thoughts from _think stage in 'react' mode\n",
    "            plan = self.planner.plan if self.use_plan else None\n",
    "            tool_info = await self.tool_recommender.get_recommended_tool_info(context=context, plan=plan)\n",
    "        else:\n",
    "            tool_info = \"\"\n",
    "\n",
    "        # data info\n",
    "        await self._check_data()\n",
    "\n",
    "        while not success and counter < max_retry:\n",
    "            ### write code ###\n",
    "            code, cause_by = await self._write_code(counter, plan_status, tool_info)\n",
    "\n",
    "            self.working_memory.add(Message(content=code, role=\"assistant\", cause_by=cause_by))\n",
    "\n",
    "            ### execute code ###\n",
    "            result, success = await self.execute_code.run(code)\n",
    "            print(result)\n",
    "\n",
    "            self.working_memory.add(Message(content=result, role=\"user\", cause_by=ExecuteNbCode))\n",
    "\n",
    "            ### process execution result ###\n",
    "            counter += 1\n",
    "\n",
    "            if not success and counter >= max_retry:\n",
    "                logger.info(\"coding failed!\")\n",
    "                review, _ = await self.planner.ask_review(auto_run=False, trigger=ReviewConst.CODE_REVIEW_TRIGGER)\n",
    "                if ReviewConst.CHANGE_WORDS[0] in review:\n",
    "                    counter = 0  # redo the task again with help of human suggestions\n",
    "\n",
    "        return code, result, success\n",
    "\n",
    "    async def _write_code(\n",
    "        self,\n",
    "        counter: int,\n",
    "        plan_status: str = \"\",\n",
    "        tool_info: str = \"\",\n",
    "    ):\n",
    "        todo = self.rc.todo  # todo is WriteAnalysisCode\n",
    "        logger.info(f\"ready to {todo.name}\")\n",
    "        use_reflection = counter > 0 and self.use_reflection  # only use reflection after the first trial\n",
    "\n",
    "        user_requirement = self.get_memories()[0].content\n",
    "\n",
    "        code = await todo.run(\n",
    "            user_requirement=user_requirement,\n",
    "            plan_status=plan_status,\n",
    "            tool_info=tool_info,\n",
    "            working_memory=self.working_memory.get(),\n",
    "            use_reflection=use_reflection,\n",
    "        )\n",
    "\n",
    "        return code, todo\n",
    "\n",
    "    async def _check_data(self):\n",
    "        if (\n",
    "            not self.use_plan\n",
    "            or not self.planner.plan.get_finished_tasks()\n",
    "            or self.planner.plan.current_task.task_type\n",
    "            not in [\n",
    "                TaskType.DATA_PREPROCESS.type_name,\n",
    "                TaskType.FEATURE_ENGINEERING.type_name,\n",
    "                TaskType.MODEL_TRAIN.type_name,\n",
    "            ]\n",
    "        ):\n",
    "            return\n",
    "        logger.info(\"Check updated data\")\n",
    "        code = await CheckData().run(self.planner.plan)\n",
    "        if not code.strip():\n",
    "            return\n",
    "        result, success = await self.execute_code.run(code)\n",
    "        if success:\n",
    "            print(result)\n",
    "            data_info = DATA_INFO.format(info=result)\n",
    "            self.working_memory.add(Message(content=data_info, role=\"user\", cause_by=CheckData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afda9875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 22:28:15.120 | INFO     | __main__:__init__:24 - will only use ['scrape_web_playwright'] as tools\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a plan to achieve the goal of extracting '快讯' content from the provided webpage and organizing it into a Markdown file:\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"task_id\": \"1\",\n",
      "        \"dependent_task_ids\": [],\n",
      "        \"instruction\": \"Use a web scraping tool to retrieve the visible text from the webpage.\"\n",
      "    },\n",
      "    {\n",
      "        \"task_id\": \"2\",\n",
      "        \"dependent_task_ids\": [\"1\"],\n",
      "        \"instruction\": \"Filter out the content related to '快讯' and exclude navigation or other irrelevant elements.\"\n",
      "    },\n",
      "    {\n",
      "        \"task_id\": \"3\",\n",
      "        \"dependent_task_ids\": [\"2\"],\n",
      "        \"instruction\": \"Categorize the extracted content and format it into a Markdown table.\"\n",
      "    },\n",
      "    {\n",
      "        \"task_id\": \"4\",\n",
      "        \"dependent_task_ids\": [\"3\"],\n",
      "        \"instruction\": \"Save the formatted content into a file named '快讯.md'.\"\n",
      "    }\n",
      "]\n",
      "``` \n",
      "\n",
      "Each task is dependent on the previous one, ensuring that the process is followed step by step. Task 1 is to scrape the text, task 2 is to filter, task 3 is to organize,"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-16 22:28:24.388 | INFO     | metagpt.utils.cost_manager:update_cost:52 - Total running cost: $0.008 | Max budget: $10.000 | Current cost: $0.008, prompt_tokens: 306, completion_tokens: 251\n",
      "2024-03-16 22:28:24.389 | WARNING  | metagpt.utils.common:wrapper:571 - There is a exception in role's execution, in order to resume, we delete the newest role communication message in the role's memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and task 4 is to save the final output.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Traceback (most recent call last):\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/utils/common.py\", line 562, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py\", line 558, in run\n    rsp = await self.react()\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py\", line 529, in react\n    rsp = await self._plan_and_act()\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py\", line 489, in _plan_and_act\n    await self.planner.update_plan(goal=goal)\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/strategy/planner.py\", line 56, in update_plan\n    rsp = await WritePlan().run(context, max_tasks=max_tasks, use_tools=self.use_tools)\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/actions/ci/write_plan.py\", line 78, in run\n    rsp = await self.assign_task_type(json.loads(rsp))\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/actions/ci/write_plan.py\", line 62, in assign_task_type\n    rsp = await self.llm.aask_code(prompt, **tool_config)\nTypeError: BaseLLM.aask_code() got an unexpected keyword argument 'tools'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/utils/common.py:562\u001b[0m, in \u001b[0;36mrole_raise_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m kbi:\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py:558\u001b[0m, in \u001b[0;36mRole.run\u001b[0;34m(self, with_message)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m rsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreact()\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# Reset the next action to be taken.\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py:529\u001b[0m, in \u001b[0;36mRole.react\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrc\u001b[38;5;241m.\u001b[39mreact_mode \u001b[38;5;241m==\u001b[39m RoleReactMode\u001b[38;5;241m.\u001b[39mPLAN_AND_ACT:\n\u001b[0;32m--> 529\u001b[0m     rsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plan_and_act()\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py:489\u001b[0m, in \u001b[0;36mRole._plan_and_act\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m goal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrc\u001b[38;5;241m.\u001b[39mmemory\u001b[38;5;241m.\u001b[39mget()[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent  \u001b[38;5;66;03m# retreive latest user requirement\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplanner\u001b[38;5;241m.\u001b[39mupdate_plan(goal\u001b[38;5;241m=\u001b[39mgoal)\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# take on tasks until all finished\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/strategy/planner.py:56\u001b[0m, in \u001b[0;36mPlanner.update_plan\u001b[0;34m(self, goal, max_tasks, max_retries)\u001b[0m\n\u001b[1;32m     55\u001b[0m context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_useful_memories()\n\u001b[0;32m---> 56\u001b[0m rsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m WritePlan()\u001b[38;5;241m.\u001b[39mrun(context, max_tasks\u001b[38;5;241m=\u001b[39mmax_tasks, use_tools\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_tools)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworking_memory\u001b[38;5;241m.\u001b[39madd(Message(content\u001b[38;5;241m=\u001b[39mrsp, role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, cause_by\u001b[38;5;241m=\u001b[39mWritePlan))\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/actions/ci/write_plan.py:78\u001b[0m, in \u001b[0;36mWritePlan.run\u001b[0;34m(self, context, max_tasks, use_tools)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_tools:\n\u001b[0;32m---> 78\u001b[0m     rsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massign_task_type(json\u001b[38;5;241m.\u001b[39mloads(rsp))\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rsp\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/actions/ci/write_plan.py:62\u001b[0m, in \u001b[0;36mWritePlan.assign_task_type\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m     61\u001b[0m tool_config \u001b[38;5;241m=\u001b[39m create_func_call_config(ASSIGN_TASK_TYPE_CONFIG)\n\u001b[0;32m---> 62\u001b[0m rsp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maask_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m task_type_list \u001b[38;5;241m=\u001b[39m rsp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_type\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: BaseLLM.aask_code() got an unexpected keyword argument 'tools'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m\n\u001b[1;32m      4\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m抓取\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m中\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m的内容，并整理成markdown存档。\u001b[39m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m大概的流程：\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m- 对抽取结果进行归类，并保存成markdown表格: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdomain\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.md\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     12\u001b[0m ci \u001b[38;5;241m=\u001b[39m CodeInterpreter(use_tools\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, tools\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscrape_web_playwright\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/nest_asyncio.py:30\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m     28\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/nest_asyncio.py:98\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[1;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "File \u001b[0;32m~/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/utils/common.py:584\u001b[0m, in \u001b[0;36mrole_raise_decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^openai\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name) \u001b[38;5;129;01mor\u001b[39;00m re\u001b[38;5;241m.\u001b[39mmatch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^httpx\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m last_error\n\u001b[0;32m--> 584\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(format_trackback_info(limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[0;31mException\u001b[0m: Traceback (most recent call last):\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/utils/common.py\", line 562, in wrapper\n    return await func(self, *args, **kwargs)\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py\", line 558, in run\n    rsp = await self.react()\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py\", line 529, in react\n    rsp = await self._plan_and_act()\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/roles/role.py\", line 489, in _plan_and_act\n    await self.planner.update_plan(goal=goal)\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/strategy/planner.py\", line 56, in update_plan\n    rsp = await WritePlan().run(context, max_tasks=max_tasks, use_tools=self.use_tools)\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/actions/ci/write_plan.py\", line 78, in run\n    rsp = await self.assign_task_type(json.loads(rsp))\n  File \"/root/workspace/StreamChatPlayground/.venv/lib/python3.10/site-packages/metagpt/actions/ci/write_plan.py\", line 62, in assign_task_type\n    rsp = await self.llm.aask_code(prompt, **tool_config)\nTypeError: BaseLLM.aask_code() got an unexpected keyword argument 'tools'\n"
     ]
    }
   ],
   "source": [
    "url = \"https://pitchhub.36kr.com/financing-flash\"\n",
    "domain = \"快讯\"\n",
    "\n",
    "prompt = f\"\"\"抓取{url}中'{domain}'的内容，并整理成markdown存档。\n",
    "\n",
    "大概的流程：\n",
    "- 使用工具抓取网页中的可见文本\n",
    "- 提取网页文本中'{domain}'相关的内容。注意网页中可能包含导航，只需要抽取'{domain}'的具体内容\n",
    "- 对抽取结果进行归类，并保存成markdown表格: {domain}.md\n",
    "\"\"\"\n",
    "\n",
    "ci = CodeInterpreter(use_tools=True, tools=[\"scrape_web_playwright\"])\n",
    "asyncio.run(ci.run(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
