{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7766cf-75a4-4370-ba70-573e88e5d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 19:23:24.313 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to /Users/deryzhou/Downloads/StreamChatPlayground/notebooks\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from utils.common import load_plaintext\n",
    "\n",
    "# debug level\n",
    "from metagpt.logs import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "# make asyncio.run() works in notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f34c9",
   "metadata": {},
   "source": [
    "## LLM ä¸ tools å‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06449968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 19:23:26.922 | DEBUG    | metagpt.provider.base_llm:aask:126 - [{'role': 'user', 'content': 'ä½ å¥½'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼Œå¯ä»¥å«æˆ‘å°æ™ºğŸ¤–ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ä½ å¥½ğŸ‘‹ï¼æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹æ™ºè°±æ¸…è¨€ï¼Œå¯ä»¥å«æˆ‘å°æ™ºğŸ¤–ï¼Œå¾ˆé«˜å…´è§åˆ°ä½ ï¼Œæ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ~/.metagpt/config2.yaml\n",
    "from metagpt.config2 import config\n",
    "from metagpt.provider.zhipuai_api import ZhiPuAILLM\n",
    "# from metagpt.utils.cost_manager import CostManager\n",
    "\n",
    "llm = ZhiPuAILLM(config.llm)\n",
    "llm.use_system_prompt = False # Disable default system message\n",
    "# llm.cost_manager = CostManager()\n",
    "\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache\n",
    "def llm_aask(msg):\n",
    "    return asyncio.run(llm.aask(msg=msg))\n",
    "\n",
    "llm_aask(\"ä½ å¥½\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bec60a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**web scraping**: Asynchronously Scrape and save the HTML structure and inner text content of a web page using Playwright. \n",
      "**text extractor**: Perform extraction on the 'content' text using a large language model. \n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from metagpt.tools.tool_convert import function_docstring_to_schema\n",
    "from metagpt.tools.libs.web_scraping import scrape_web_playwright\n",
    "from tools.text_extractor.llm_extractor import llm_extractor\n",
    "\n",
    "def function_to_schema(func):\n",
    "    docstring = inspect.getdoc(func)\n",
    "    schema = function_docstring_to_schema(func, docstring)\n",
    "    schema[\"imports\"] = f\"from {func.__module__} import {func.__name__}\"\n",
    "    return schema\n",
    "\n",
    "DEF_TOOLS = [\n",
    "    (\"web scraping\", scrape_web_playwright),\n",
    "    (\"text extractor\", llm_extractor),\n",
    "]\n",
    "tools = {}\n",
    "for name, func in DEF_TOOLS:\n",
    "    schema = function_to_schema(func)\n",
    "    tools[name] = schema\n",
    "\n",
    "task_types = \"\\n\".join([\n",
    "    f\"**{k}**: {v['description']}\" for k,v in tools.items()\n",
    "])\n",
    "print(task_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7def00e",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23786658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-21 19:31:16.821 | DEBUG    | __main__:create_plan:33 - Respond to the human as helpfully and accurately as possible.\n",
      "\n",
      "# User goal\n",
      "æŠ“å– https://pitchhub.36kr.com/financing-flash ä¸­'å¿«è®¯'çš„å†…å®¹ï¼Œå¹¶æ•´ç†æˆmarkdownå­˜æ¡£\n",
      "\n",
      "å¤§æ¦‚çš„æµç¨‹ï¼š\n",
      "- ä½¿ç”¨å·¥å…·æŠ“å–ç½‘é¡µä¸­çš„å¯è§æ–‡æœ¬\n",
      "- æå–ç½‘é¡µæ–‡æœ¬ä¸­'å¿«è®¯'ç›¸å…³çš„å†…å®¹ã€‚æ³¨æ„ç½‘é¡µä¸­å¯èƒ½åŒ…å«å¯¼èˆªï¼Œåªéœ€è¦æŠ½å–'å¿«è®¯'çš„å…·ä½“å†…å®¹\n",
      "- å¯¹æŠ½å–ç»“æœè¿›è¡Œå½’ç±»ï¼Œå¹¶ä¿å­˜æˆmarkdownè¡¨æ ¼: å¿«è®¯.md\n",
      "\n",
      "# Available Task Types:\n",
      "**web scraping**: Asynchronously Scrape and save the HTML structure and inner text content of a web page using Playwright. \n",
      "**text extractor**: Perform extraction on the 'content' text using a large language model. \n",
      "\n",
      "# Task:\n",
      "Based on the user goal, write a plan or modify an existing plan of what you should do to achieve the goal. A plan consists of one to 20 tasks.\n",
      "If you are modifying an existing plan, carefully follow the instruction, don't make unnecessary changes. Give the whole plan unless instructed to modify only one task of the plan.\n",
      "If you encounter errors on the current task, revise and output the current single task only.\n",
      "Output a list of jsons following the format:\n",
      "```json\n",
      "[\n",
      "    {{\n",
      "        \"task_id\": str = \"unique identifier for a task in plan, can be an ordinal\",\n",
      "        \"dependent_task_ids\": list[str] = \"ids of tasks prerequisite to this task\",\n",
      "        \"instruction\": \"what you should do in this task, one short phrase or sentence\",\n",
      "        \"task_type\": \"type of this task, should be one of Available Task Types\",\n",
      "    }},\n",
      "    ...\n",
      "]\n",
      "```\n",
      "2024-03-21 19:31:16.822 | DEBUG    | __main__:create_plan:40 - [Task(task_id='1', dependent_task_ids=[], instruction='Scrape the HTML and inner text content of the webpage.', task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='2', dependent_task_ids=['1'], instruction='Extract the visible text content from the scraped HTML.', task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='3', dependent_task_ids=['2'], instruction=\"Identify and extract sections of the text containing the keyword 'å¿«è®¯'.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='4', dependent_task_ids=['3'], instruction='Clean up the extracted text to remove any navigation or non-essential content.', task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='5', dependent_task_ids=['4'], instruction='Organize the extracted content into a structured format suitable for Markdown.', task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='6', dependent_task_ids=['5'], instruction=\"Save the structured content into a Markdown file named 'å¿«è®¯.md'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plan(goal=\"æŠ“å– https://pitchhub.36kr.com/financing-flash ä¸­'å¿«è®¯'çš„å†…å®¹ï¼Œå¹¶æ•´ç†æˆmarkdownå­˜æ¡£\", context='', tasks=[Task(task_id='1', dependent_task_ids=[], instruction='Scrape the HTML and inner text content of the webpage.', task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='2', dependent_task_ids=['1'], instruction='Extract the visible text content from the scraped HTML.', task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='3', dependent_task_ids=['2'], instruction=\"Identify and extract sections of the text containing the keyword 'å¿«è®¯'.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='4', dependent_task_ids=['3'], instruction='Clean up the extracted text to remove any navigation or non-essential content.', task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='5', dependent_task_ids=['4'], instruction='Organize the extracted content into a structured format suitable for Markdown.', task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='6', dependent_task_ids=['5'], instruction=\"Save the structured content into a Markdown file named 'å¿«è®¯.md'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False)], task_map={'1': Task(task_id='1', dependent_task_ids=[], instruction='Scrape the HTML and inner text content of the webpage.', task_type='web scraping', code='', result='', is_success=False, is_finished=False), '2': Task(task_id='2', dependent_task_ids=['1'], instruction='Extract the visible text content from the scraped HTML.', task_type='web scraping', code='', result='', is_success=False, is_finished=False), '3': Task(task_id='3', dependent_task_ids=['2'], instruction=\"Identify and extract sections of the text containing the keyword 'å¿«è®¯'.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False), '4': Task(task_id='4', dependent_task_ids=['3'], instruction='Clean up the extracted text to remove any navigation or non-essential content.', task_type='text extractor', code='', result='', is_success=False, is_finished=False), '5': Task(task_id='5', dependent_task_ids=['4'], instruction='Organize the extracted content into a structured format suitable for Markdown.', task_type='text extractor', code='', result='', is_success=False, is_finished=False), '6': Task(task_id='6', dependent_task_ids=['5'], instruction=\"Save the structured content into a Markdown file named 'å¿«è®¯.md'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False)}, current_task_id='1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from metagpt.schema import Plan, Task\n",
    "from metagpt.utils.common import OutputParser\n",
    "\n",
    "\n",
    "def load_prompts(path: str) -> PromptTemplate:\n",
    "    base_path = os.path.join(\"prompts\", path)\n",
    "    output_format = load_plaintext(base_path, \"output.md\")\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template=load_plaintext(base_path, \"template.yaml\"),\n",
    "    )\n",
    "    return prompt.partial(output=output_format)\n",
    "\n",
    "def parse_json(rsp):\n",
    "    try:\n",
    "        objs = json.loads(rsp)\n",
    "    except:\n",
    "        code_block = OutputParser.parse_code(rsp, \"json\")\n",
    "        objs = json.loads(code_block)\n",
    "    return objs\n",
    "\n",
    "def create_plan(goal, guidance):\n",
    "    plan_prompt = load_prompts(\"planning\")\n",
    "    template = plan_prompt.format(\n",
    "        goal=goal,\n",
    "        user_guidance=guidance,\n",
    "        task_types=task_types,\n",
    "        max_tasks=20,\n",
    "    )\n",
    "    logger.debug(template)\n",
    "\n",
    "    plan = Plan(goal=goal)\n",
    "    rsp = llm_aask(msg=template)\n",
    "\n",
    "    tasks_json = parse_json(rsp)\n",
    "    tasks = [Task(**task_config) for task_config in tasks_json]\n",
    "    logger.debug(tasks)\n",
    "\n",
    "    plan.add_tasks(tasks)\n",
    "    return plan\n",
    "\n",
    "\n",
    "user_goal = \"æŠ“å– https://pitchhub.36kr.com/financing-flash ä¸­'å¿«è®¯'çš„å†…å®¹ï¼Œå¹¶æ•´ç†æˆmarkdownå­˜æ¡£\"\n",
    "user_guidance = \"\"\"å¤§æ¦‚çš„æµç¨‹ï¼š\n",
    "- ä½¿ç”¨å·¥å…·æŠ“å–ç½‘é¡µä¸­çš„å¯è§æ–‡æœ¬\n",
    "- æå–ç½‘é¡µæ–‡æœ¬ä¸­'å¿«è®¯'ç›¸å…³çš„å†…å®¹ã€‚æ³¨æ„ç½‘é¡µä¸­å¯èƒ½åŒ…å«å¯¼èˆªï¼Œåªéœ€è¦æŠ½å–'å¿«è®¯'çš„å…·ä½“å†…å®¹\n",
    "- å¯¹æŠ½å–ç»“æœè¿›è¡Œå½’ç±»ï¼Œå¹¶ä¿å­˜æˆmarkdownè¡¨æ ¼: å¿«è®¯.md\"\"\"\n",
    "\n",
    "plan = create_plan(goal=user_goal, guidance=user_guidance)\n",
    "plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a73f9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task(task_id='1', dependent_task_ids=[], instruction='Scrape the HTML and inner text content of the webpage.', task_type='web scraping', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='2', dependent_task_ids=['1'], instruction='Extract the visible text content from the scraped HTML.', task_type='web scraping', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='3', dependent_task_ids=['2'], instruction=\"Identify and extract sections of the text containing the keyword 'å¿«è®¯'.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='4', dependent_task_ids=['3'], instruction='Clean up the extracted text to remove any navigation or non-essential content.', task_type='text extractor', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='5', dependent_task_ids=['4'], instruction='Organize the extracted content into a structured format suitable for Markdown.', task_type='text extractor', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='6', dependent_task_ids=['5'], instruction=\"Save the structured content into a Markdown file named 'å¿«è®¯.md'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(plan.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669eb4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
