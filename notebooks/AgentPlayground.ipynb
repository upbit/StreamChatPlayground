{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba7766cf-75a4-4370-ba70-573e88e5d7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 09:05:19.741 | INFO     | metagpt.const:get_metagpt_package_root:29 - Package root set to /root/workspace/StreamChatPlayground/notebooks\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from utils.common import load_plaintext\n",
    "\n",
    "# debug level\n",
    "from metagpt.logs import logger\n",
    "logger.remove()\n",
    "logger.add(sys.stderr, level=\"DEBUG\")\n",
    "\n",
    "# make asyncio.run() works in notebook\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f34c9",
   "metadata": {},
   "source": [
    "## LLM 与 tools 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f19600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 智普AI\n",
    "# ~/.metagpt/config2.yaml\n",
    "from metagpt.config2 import config\n",
    "from metagpt.provider.zhipuai_api import ZhiPuAILLM\n",
    "# from metagpt.utils.cost_manager import CostManager\n",
    "\n",
    "llm = ZhiPuAILLM(config.llm)\n",
    "llm.use_system_prompt = False # Disable default system message\n",
    "# llm.cost_manager = CostManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ead1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vllm 本地\n",
    "import yaml\n",
    "from metagpt.configs.llm_config import LLMConfig\n",
    "from metagpt.provider.openai_api import OpenAILLM\n",
    "# from metagpt.utils.cost_manager import CostManager\n",
    "\n",
    "llm_configs = yaml.safe_load(load_plaintext(\"../\", \"vllm_local.yaml\"))\n",
    "llm_config = LLMConfig.model_validate(llm_configs['llm'])\n",
    "llm = OpenAILLM(llm_config)\n",
    "llm.use_system_prompt = False # Disable default system message\n",
    "# llm.cost_manager = CostManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06449968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 09:05:40.166 | DEBUG    | metagpt.provider.base_llm:aask:126 - [{'role': 'user', 'content': '你好，你是谁？'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个大型语言模型，由 Google 训练。我是一个语言模型，可以提供各种各样的信息和帮助。\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我是一个大型语言模型，由 Google 训练。我是一个语言模型，可以提供各种各样的信息和帮助。'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache\n",
    "def llm_aask(msg):\n",
    "    return asyncio.run(llm.aask(msg=msg))\n",
    "\n",
    "llm_aask(\"你好，你是谁？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec60a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**web scraping**: Asynchronously Scrape and save the HTML structure and inner text content of a web page using Playwright. \n",
      "**text extractor**: Perform extraction on the 'content' text using a large language model. \n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "from metagpt.tools.tool_convert import function_docstring_to_schema\n",
    "from metagpt.tools.libs.web_scraping import scrape_web_playwright\n",
    "from tools.text_extractor.llm_extractor import llm_extractor\n",
    "\n",
    "def function_to_schema(func):\n",
    "    docstring = inspect.getdoc(func)\n",
    "    schema = function_docstring_to_schema(func, docstring)\n",
    "    schema[\"imports\"] = f\"from {func.__module__} import {func.__name__}\"\n",
    "    return schema\n",
    "\n",
    "DEF_TOOLS = [\n",
    "    (\"web scraping\", scrape_web_playwright),\n",
    "    (\"text extractor\", llm_extractor),\n",
    "]\n",
    "tools = {}\n",
    "for name, func in DEF_TOOLS:\n",
    "    schema = function_to_schema(func)\n",
    "    tools[name] = schema\n",
    "\n",
    "task_types = \"\\n\".join([\n",
    "    f\"**{k}**: {v['description']}\" for k,v in tools.items()\n",
    "])\n",
    "print(task_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7def00e",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23786658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 09:05:50.816 | DEBUG    | __main__:create_plan:33 - Respond to the human as helpfully and accurately as possible.\n",
      "\n",
      "# User goal\n",
      "抓取 https://pitchhub.36kr.com/financing-flash 中'快讯'的内容，并整理成markdown存档\n",
      "\n",
      "大概的流程：\n",
      "- 使用工具抓取网页中的可见文本\n",
      "- 提取网页文本中'快讯'相关的内容。注意网页中可能包含导航，只需要抽取'快讯'的具体内容\n",
      "- 对抽取结果进行归类，并保存成markdown表格: 快讯.md\n",
      "\n",
      "# Available Task Types:\n",
      "**web scraping**: Asynchronously Scrape and save the HTML structure and inner text content of a web page using Playwright. \n",
      "**text extractor**: Perform extraction on the 'content' text using a large language model. \n",
      "\n",
      "# Task:\n",
      "Based on the user goal, write a plan or modify an existing plan of what you should do to achieve the goal. A plan consists of one to 20 tasks.\n",
      "If you are modifying an existing plan, carefully follow the instruction, don't make unnecessary changes. Give the whole plan unless instructed to modify only one task of the plan.\n",
      "If you encounter errors on the current task, revise and output the current single task only.\n",
      "Output a list of jsons following the format:\n",
      "```json\n",
      "[\n",
      "    {{\n",
      "        \"task_id\": str = \"unique identifier for a task in plan, can be an ordinal\",\n",
      "        \"dependent_task_ids\": list[str] = \"ids of tasks prerequisite to this task\",\n",
      "        \"instruction\": \"what you should do in this task, one short phrase or sentence\",\n",
      "        \"task_type\": \"type of this task, should be one of Available Task Types\",\n",
      "    }},\n",
      "    ...\n",
      "]\n",
      "```\n",
      "2024-03-23 09:05:50.816 | DEBUG    | metagpt.provider.base_llm:aask:126 - [{'role': 'user', 'content': 'Respond to the human as helpfully and accurately as possible.\\n\\n# User goal\\n抓取 https://pitchhub.36kr.com/financing-flash 中\\'快讯\\'的内容，并整理成markdown存档\\n\\n大概的流程：\\n- 使用工具抓取网页中的可见文本\\n- 提取网页文本中\\'快讯\\'相关的内容。注意网页中可能包含导航，只需要抽取\\'快讯\\'的具体内容\\n- 对抽取结果进行归类，并保存成markdown表格: 快讯.md\\n\\n# Available Task Types:\\n**web scraping**: Asynchronously Scrape and save the HTML structure and inner text content of a web page using Playwright. \\n**text extractor**: Perform extraction on the \\'content\\' text using a large language model. \\n\\n# Task:\\nBased on the user goal, write a plan or modify an existing plan of what you should do to achieve the goal. A plan consists of one to 20 tasks.\\nIf you are modifying an existing plan, carefully follow the instruction, don\\'t make unnecessary changes. Give the whole plan unless instructed to modify only one task of the plan.\\nIf you encounter errors on the current task, revise and output the current single task only.\\nOutput a list of jsons following the format:\\n```json\\n[\\n    {{\\n        \"task_id\": str = \"unique identifier for a task in plan, can be an ordinal\",\\n        \"dependent_task_ids\": list[str] = \"ids of tasks prerequisite to this task\",\\n        \"instruction\": \"what you should do in this task, one short phrase or sentence\",\\n        \"task_type\": \"type of this task, should be one of Available Task Types\",\\n    }},\\n    ...\\n]\\n```'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Plan\n",
      "\n",
      "**Goal:** Grab content of '快讯' from the website \"pitchhub.36kr.com/financing-flash\" and organize it into a markdown file.\n",
      "\n",
      "**Tasks:**\n",
      "\n",
      "```json\n",
      "[\n",
      "    {\n",
      "        \"task_id\": \"1\",\n",
      "        \"dependent_task_ids\": [],\n",
      "        \"instruction\": \"Open the website 'pitchhub.36kr.com/financing-flash'.\",\n",
      "        \"task_type\": \"web scraping\"\n",
      "    },\n",
      "    {\n",
      "        \"task_id\": \"2\",\n",
      "        \"dependent_task_ids\": [\"1\"],\n",
      "        \"instruction\": \"Navigate to the '快讯' section on the website.\",\n",
      "        \"task_type\": \"web scraping\"\n",
      "    },\n",
      "    {\n",
      "        \"task_id\": \"3\",\n",
      "        \"dependent_task_ids\": [\"2\"],\n",
      "        \"instruction\": \"Copy the text content of the '快讯' section.\",\n",
      "        \"task_type\": \"text extractor\"\n",
      "    },\n",
      "    {\n",
      "        \"task_id\": \"4\",\n",
      "        \"dependent_task_ids\": [\"3\"],\n",
      "        \"instruction\": \"Save the copied text content into a separate file named '快讯.md'.\",\n",
      "        \"task_type\": \"file management\"\n",
      "    }\n",
      "]\n",
      "```\n",
      "\n",
      "**Notes:**\n",
      "\n",
      "- This plan includes the tasks necessary to achieve the user goal of grabbing content from '快讯' and saving it into a markdown file.\n",
      "- The tasks are listed in the order they should be completed.\n",
      "- The 'dependent_task_ids' attribute specifies the tasks that must be completed before the current task can be started.\n",
      "- The 'task_type' attribute specifies the type of task that"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 09:06:01.686 | DEBUG    | __main__:create_plan:40 - [Task(task_id='1', dependent_task_ids=[], instruction=\"Open the website 'pitchhub.36kr.com/financing-flash'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='2', dependent_task_ids=['1'], instruction=\"Navigate to the '快讯' section on the website.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='3', dependent_task_ids=['2'], instruction=\"Copy the text content of the '快讯' section.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='4', dependent_task_ids=['3'], instruction=\"Save the copied text content into a separate file named '快讯.md'.\", task_type='file management', code='', result='', is_success=False, is_finished=False)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " should be performed for each task.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Plan(goal=\"抓取 https://pitchhub.36kr.com/financing-flash 中'快讯'的内容，并整理成markdown存档\", context='', tasks=[Task(task_id='1', dependent_task_ids=[], instruction=\"Open the website 'pitchhub.36kr.com/financing-flash'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='2', dependent_task_ids=['1'], instruction=\"Navigate to the '快讯' section on the website.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False), Task(task_id='3', dependent_task_ids=['2'], instruction=\"Copy the text content of the '快讯' section.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False), Task(task_id='4', dependent_task_ids=['3'], instruction=\"Save the copied text content into a separate file named '快讯.md'.\", task_type='file management', code='', result='', is_success=False, is_finished=False)], task_map={'1': Task(task_id='1', dependent_task_ids=[], instruction=\"Open the website 'pitchhub.36kr.com/financing-flash'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False), '2': Task(task_id='2', dependent_task_ids=['1'], instruction=\"Navigate to the '快讯' section on the website.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False), '3': Task(task_id='3', dependent_task_ids=['2'], instruction=\"Copy the text content of the '快讯' section.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False), '4': Task(task_id='4', dependent_task_ids=['3'], instruction=\"Save the copied text content into a separate file named '快讯.md'.\", task_type='file management', code='', result='', is_success=False, is_finished=False)}, current_task_id='1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain.prompts import PromptTemplate\n",
    "from metagpt.schema import Plan, Task\n",
    "from metagpt.utils.common import OutputParser\n",
    "\n",
    "\n",
    "def load_prompts(path: str) -> PromptTemplate:\n",
    "    base_path = os.path.join(\"prompts\", path)\n",
    "    output_format = load_plaintext(base_path, \"output.md\")\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[],\n",
    "        template=load_plaintext(base_path, \"template.yaml\"),\n",
    "    )\n",
    "    return prompt.partial(output=output_format)\n",
    "\n",
    "def parse_json(rsp):\n",
    "    try:\n",
    "        objs = json.loads(rsp)\n",
    "    except:\n",
    "        code_block = OutputParser.parse_code(rsp, \"json\")\n",
    "        objs = json.loads(code_block)\n",
    "    return objs\n",
    "\n",
    "def create_plan(goal, guidance):\n",
    "    plan_prompt = load_prompts(\"planning\")\n",
    "    template = plan_prompt.format(\n",
    "        goal=goal,\n",
    "        user_guidance=guidance,\n",
    "        task_types=task_types,\n",
    "        max_tasks=20,\n",
    "    )\n",
    "    logger.debug(template)\n",
    "\n",
    "    plan = Plan(goal=goal)\n",
    "    rsp = llm_aask(msg=template)\n",
    "\n",
    "    tasks_json = parse_json(rsp)\n",
    "    tasks = [Task(**task_config) for task_config in tasks_json]\n",
    "    logger.debug(tasks)\n",
    "\n",
    "    plan.add_tasks(tasks)\n",
    "    return plan\n",
    "\n",
    "\n",
    "user_goal = \"抓取 https://pitchhub.36kr.com/financing-flash 中'快讯'的内容，并整理成markdown存档\"\n",
    "user_guidance = \"\"\"大概的流程：\n",
    "- 使用工具抓取网页中的可见文本\n",
    "- 提取网页文本中'快讯'相关的内容。注意网页中可能包含导航，只需要抽取'快讯'的具体内容\n",
    "- 对抽取结果进行归类，并保存成markdown表格: 快讯.md\"\"\"\n",
    "\n",
    "plan = create_plan(goal=user_goal, guidance=user_guidance)\n",
    "plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a73f9842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task(task_id='1', dependent_task_ids=[], instruction=\"Open the website 'pitchhub.36kr.com/financing-flash'.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='2', dependent_task_ids=['1'], instruction=\"Navigate to the '快讯' section on the website.\", task_type='web scraping', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='3', dependent_task_ids=['2'], instruction=\"Copy the text content of the '快讯' section.\", task_type='text extractor', code='', result='', is_success=False, is_finished=False),\n",
      " Task(task_id='4', dependent_task_ids=['3'], instruction=\"Save the copied text content into a separate file named '快讯.md'.\", task_type='file management', code='', result='', is_success=False, is_finished=False)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(plan.tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669eb4e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
